{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient and AutoGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOGRAD: ìë™ ë¯¸ë¶„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- autograd íŒ¨í‚¤ì§€ëŠ” Tensorì˜ ëª¨ë“  ì—°ì‚°ì— ëŒ€í•´ ìë™ ë¯¸ë¶„ì„ ì œê³µí•œë‹¤. \n",
    "- ì´ëŠ” define-by-runì´ë¼ëŠ” í”„ë ˆì„ ì›Œí¬ë¡œ ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì‘ì„±í•˜ëŠëƒì— ë”°ë¼ ì—­ì „íŒŒê°€ ì •ì˜ëœë‹¤ëŠ” ëœ»ì´ë©°, ì—­ì „íŒŒëŠ” í•™ìŠµ ê³¼ì •ì˜ ë§¤ ë‹¨ê³„ë§ˆë‹¤ ë‹¬ë¼ì§„ë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- íŒ¨í‚¤ì§€ ì¤‘ì‹¬ì—ëŠ” torch.Tensor í´ë˜ìŠ¤ê°€ ìˆë‹¤.\n",
    "- ë§Œì•½ .requires_grad ì†ì„±ì„ Trueë¡œ ì„¤ì •í•˜ë©´, ê·¸ tensorì—ì„œ ì´ë¤„ì§„ ëª¨ë“  ì—°ì‚°ë“¤ì„ ì¶”ì í•™ê¸° ì‹œì‘í•œë‹¤. \n",
    "- ê³„ì‚°ì´ ì™„ë£Œëœ í›„, .backward()ë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë“  ë³€í™”ë„(gradient)ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.\n",
    "- ì´ Tensorì˜ ë³€í™”ë„ëŠ” .grad ì†ì„±ì— ëˆ„ì ëœë‹¤.\n",
    "- Tensorê°€ ê¸°ë¡ì„ ì¶”ì í•˜ëŠ” ê²ƒì„ ì¤‘ë‹¨í•˜ê²Œ í•˜ë ¤ë©´, .detach()ë¥¼ í˜¸ì¶œí•˜ì—¬ ì—°ì‚° ê¸°ë¡ìœ¼ë¡œë¶€í„° ë¶„ë¦¬í•˜ì—¬ ì—°ì‚°ë“¤ì´ ì¶”ì ë˜ëŠ” ê²ƒì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤. \n",
    "- ê¸°ë¡ì„ ì¶”ì í•˜ëŠ” ê²ƒ(ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©)ì„ ë°©ì§€í•˜ê¸° ìœ„í•´, ì½”ë“œ ë¸”ëŸ­ì„ with torch.no_grad()ë¡œ ê°ìŒ€ ìˆ˜ ìˆë‹¤.\n",
    "- ì´ëŠ” íŠ¹íˆ gradientëŠ” í•„ìš”ì—†ì§€ë§Œ, require_grad = True ê°€ ì„¤ì •ë˜ì–´ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°–ëŠ” ëª¨ë¸ì„ í‰ê°€í•  ë•Œ ìœ ìš©í•˜ë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Autograd êµ¬í˜„ì—ì„œ ì¤‘ìš”í•œ í´ë˜ìŠ¤ê°€ í•˜ë‚˜ ë” ìˆëŠ”ë°, ë°”ë¡œ Function í´ë˜ìŠ¤ì´ë‹¤. \n",
    "- Tensorì™€ Functionì€ ìƒí˜¸ ì—°ê²° ë˜ì–´ìˆìœ¼ë©°, ëª¨ë“  ì—°ì‚° ê³¼ì •ì„ ë¶€í˜¸í™”í•˜ì—¬ acycllic graphë¥¼ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "- ê° tensorëŠ” .grad_fn ì†ì„±ì„ ê°–ê³  ìˆëŠ”ë°, ì´ëŠ” Tensorë¥¼ ìƒì„±í•œ Functionì„ ì°¸ì¡°í•˜ê³  ìˆë‹¤. (ì‚¬ìš©ìê°€ ë§Œë“  í…ì„œëŠ” ì˜ˆì™¸ë¡œ ì´ ë•Œ grad_fnì€ Noneì´ë‹¤.)\n",
    "\n",
    "\n",
    "- derivativeë¥¼ ê³„ì‚°í•˜ê¸± ìœ„í•´ì„œëŠ” Tensorì˜ .backward()ë¥¼ í˜¸ì¶œí•˜ë©´ ëœë‹¤. \n",
    "- ë§Œì•½ Tensorê°€ ìŠ¤ì¹¼ë¼ì¸ ê²½ìš°ì—ëŠ” backwardì— ì¸ìë¥¼ ì •í•´ì¤„ í•„ìš”ê°€ ì—†ë‹¤. í•˜ì§€ë§Œ ì—¬ëŸ¬ ê°œ ìš”ì†Œë¥¼ ê°–ê³  ìˆì„ ë•ŒëŠ” tensorì˜ ëª¨ì–‘ì„ gradient ì¸ìë¡œ ì§€ì •í•  í•„ìš”ê°€ ìˆë‹¤. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor ìƒì„± í›„, requires_grad= True ë¥¼ ì„¤ì •í•˜ì—¬ ì—°ì‚°ì„ ê¸°ë¡í•œë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x= torch.ones(2,2,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorì— ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- yëŠ” ì—°ì‚°ì˜ ê²°ê³¼ë¡œ ìƒì„±ëœ ê²ƒì´ë¯€ë¡œ grad_fn ì„ ê°€ì§„ë‹¤.\n",
    "- ë°˜ë©´ xëŠ” ì‚¬ìš©ìê°€ ë§Œë“  tensorì´ë¯€ë¡œ grad_fnì€ Noneì„ ê°€ì§„ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x11db1a7f0>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)\n",
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .requires_grad_()ëŠ” ê¸°ì¡´ Tensorì˜ requires_grad ê°’ì„ in-placeí•˜ì—¬ ë³€ê²½í•œë‹¤..\n",
    "- ì…ë ¥ê°’ì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ì€ Falseì´ë‹¤. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1818,  0.6418],\n",
      "        [-0.5078,  1.0462]])\n",
      "tensor([[-0.6664, -5.3742],\n",
      "        [ 1.0104, 67.9117]])\n",
      "False\n",
      "None\n",
      "True\n",
      "True\n",
      "<SumBackward0 object at 0x11db30a58>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,2)\n",
    "print(a)\n",
    "a = ((a*3) /(a-1))\n",
    "print(a)\n",
    "print(a.requires_grad) # false\n",
    "print(a.grad_fn) # None ì‚¬ìš©ìê°€ ì§ì ‘ë§Œë“  tensorì´ë¯€ë¡œ \n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad) # True\n",
    "b = (a*a).sum() \n",
    "print(b.requires_grad) # False\n",
    "print(b.grad_fn) # sumbackward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë³€í™”ë„ (GRADIENT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì´ì œ ì—­ì „íŒŒ(backprop)ë¥¼ í•´ë³´ê² ë‹¤. outì€ í•˜ë‚˜ì˜ ìŠ¤ì¹¼ë¼ ê°’ë§Œ ê°–ê³  ìˆê¸° ë•Œë¬¸ì—\n",
    "- out.backward()ëŠ” out.backward(torch.tensor(1.))ê³¼ ë™ì¼í•˜ë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë³€í™”ë„ d(out)/dxë¥¼ ì¶œë ¥í•œë‹¤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad) # partial o / partial x_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ìˆ˜í•™ì ìœ¼ë¡œ ë²¡í„° í•¨ìˆ˜ ğ‘¦âƒ— =ğ‘“(ğ‘¥âƒ— ) ì—ì„œ ğ‘¥âƒ—  ì— ëŒ€í•œ ğ‘¦âƒ—  ì˜ ë³€í™”ë„ëŠ” ì•¼ì½”ë¹„ì•ˆ í–‰ë ¬(Jacobian Matrix)ì…ë‹ˆë‹¤:\n",
    "- ì¼ë°˜ì ìœ¼ë¡œ, torch.autogradëŠ” ë²¡í„°-ì•¼ì½”ë¹„ì•ˆ ê³±ì„ ê³„ì‚°í•˜ëŠ” ì—”ì§„ì´ë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0617, -0.5153,  0.5985], requires_grad=True)\n",
      "tensor([  126.4052, -1055.3285,  1225.8296], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x =  torch.randn(3, requires_grad =True)\n",
    "y = x *2\n",
    "while y.data.norm() < 1000:\n",
    "    y= y*2\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì´ ê²½ìš° yëŠ” ë” ì´ìƒ ìŠ¤ì¹¼ë¼ ê°’ì´ ì•„ë‹ˆë‹¤. torch.autogradëŠ” ì „ì²´ ì•¼ì½”ë¹„ì•ˆì„ ì§ì ‘ ê³„ì‚°í•  ìˆ˜ ì—†ì§€ë§Œ, ë²¡í„° ì•¼ì½”ë¹„ì•ˆ ê³±ì€ ê°„ë‹¨íˆ backwardì— í•´ë‹¹ ë²¡í„°ë¥¼ ì¸ìë¡œ ì œê³µí•˜ì—¬ ì–»ì„ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1,1.0, 0.0001], dtype = torch.float)\n",
    "y.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë˜í•œ with torch.no_grad(): ë¡œ ì½”ë“œ ë¸”ëŸ­ì„ ê°ì‹¸ì„œ \n",
    "- autogradê°€ .requires_grad=True ì¸ í…ì„œì˜ ì—°ì‚°ê¸°ë¡ì„ ì¶”ì í•˜ëŠ” ê²ƒì„ ë©ˆì¶œ ìˆ˜ ìˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
